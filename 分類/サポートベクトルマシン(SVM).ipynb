{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR_DATASET_PATH = '../datasets/HR_comma_sep.csv'\n",
    "hr_df = pd.read_csv(HR_DATASET_PATH)\n",
    "hr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 10)\n",
      "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
      "       'average_montly_hours', 'time_spend_company', 'Work_accident', 'left',\n",
      "       'promotion_last_5years', 'sales', 'salary'],\n",
      "      dtype='object')\n",
      "satisfaction_level       False\n",
      "last_evaluation          False\n",
      "number_project           False\n",
      "average_montly_hours     False\n",
      "time_spend_company       False\n",
      "Work_accident            False\n",
      "left                     False\n",
      "promotion_last_5years    False\n",
      "sales                    False\n",
      "salary                   False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(hr_df.shape)\n",
    "print(hr_df.columns)\n",
    "print(hr_df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# salary(給与水準)をダミー変数へ置換する\n",
    "hr_df.salary.replace({'low': 1, 'medium': 2, 'high': 3}, inplace=True)\n",
    "# salesをダミー変数へ\n",
    "hr_df = pd.get_dummies(hr_df, columns=['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サポートベクトルマシン(SVM: Support Vector Machine)\n",
    "*SVMは線形二値分類器であり、非常に高い分類性能を持つことで知られている。また、後に説明するカーネル法を組み合わせて用いれば、SVMは非線形な分類も可能である。*\n",
    "\n",
    " - **正クラス(positive class)**\n",
    " - **負クラス(negative class)**\n",
    " - **正例**(positive example, positive instance)\n",
    " - **負例**(negative example, negative instance)\n",
    "\n",
    "訓練データ$D$は、\n",
    "$$\n",
    "D=\\left\\{ \\left( x^{ (1) },y^{ (1) } \\right) ,\\left( x^{ (2) },y^{ (2) } \\right) ,\\cdots ,\\left( x^{ (\\left| D \\right| ) },y^{ (\\left| D \\right| ) } \\right)  \\right\\} \n",
    "$$\n",
    "と与えられているとしよう。\n",
    "\n",
    " - $x^{(i)}$: 特徴ベクトル\n",
    " - $y^{ (i) }=\\begin{cases} 正例のクラスラベル:\\quad +1 \\\\ 負例のクラスラベル:\\quad -1 \\end{cases}$\n",
    "\n",
    "SVMは線形分類器であるので、分離平面の方向ベクトル$w$と切片$b$をパラメータとして、\n",
    "$$\n",
    "f\\left(x\\right) = w \\cdot x - b\n",
    "$$\n",
    "という関数を用いて表される。特徴ベクトル$x$を、$f\\left(x\\right) \\ge 0$ならば正クラス、$f\\left(x\\right) < 0$ならば負クラスに分類する。\n",
    "\n",
    " - [scikit-learn 0.19.0 documentation - sklearn.svm: Support Vector Machines](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サポートベクトルマシンの導出\n",
    "> $d$次元の訓練データが分布しているとして、これらを正クラス、負クラスに分類する**分離平面(separating plane)**を構築したい。\n",
    "\n",
    " - $w$: 方向ベクトル\n",
    " - $b$: 切片\n",
    "\n",
    "分離平面は$f\\left(x\\right) = 0$であるので、最適な分離平面は、\n",
    "$$\n",
    "f\\left(x\\right) = w \\cdot x - b = 0\\\\\n",
    "w \\cdot x = b\n",
    "$$\n",
    "を満たす点$x$の集合になる。このときのパラメータ$w$と$b$を求める。\n",
    "\n",
    "そして、この最適な分離平面は**<font color=\"blue\">マージン最大化</font>**(margin maximization)とよばれる「どちらのクラスからもなるべく遠い位置で分ける」戦略から導出する。\n",
    "\n",
    " - マージン(margin): 最も近い特徴ベクトルへの距離\n",
    "\n",
    "![](http://www.cis.doshisha.ac.jp/mjin/R/31/fig04.PNG)\n",
    "\n",
    " - $x_{+}$: 分離平面に最も近くにある正例\n",
    " - $x_{\\ast}$: それぞれの$x_{+}, x_{-}$と分離平面を結ぶ垂直の足\n",
    "\n",
    "マージンは、\n",
    "$$\n",
    "\\left| { x }_{ + }-{ x }_{ \\ast  } \\right| \n",
    "$$\n",
    "と表される。$w$は$f\\left(x\\right) = 0$の分離平面と直交しているので$w$と${ x }_{ + }-{ x }_{ \\ast  }$は同じ方向を向いているので、\n",
    "$$\n",
    "w \\cdot (x_{+} - x_{\\ast}) = \\left| w \\right|\\left| x_{+} - x_{\\ast}\\right|\n",
    "$$\n",
    "が成り立つ。\n",
    "\n",
    "さて、分離平面$w \\cdot w = b$は、式全体を定数倍しても変わらない。逆にいえば、うまく定数倍すれば\n",
    "$$\n",
    "w \\cdot w_{+} - b = 1\n",
    "$$\n",
    "とすることもできる。このようにパラメータが調整されているとしよう。また、$x_{\\ast}$は分離平面上にあるので、当然ながら\n",
    "$$\n",
    "w \\cdot w_{\\ast} = b\n",
    "$$\n",
    "である。よって、\n",
    "$$\n",
    "w \\cdot ({ x }_{ + }-{ x }_{ \\ast  }) = w \\cdot x_{+} - w \\cdot x_{\\ast} = (b+1) - b = 1\n",
    "$$\n",
    "となる。$w \\cdot ({ x }_{ + }-{ x }_{ \\ast  }) = \\left| w \\right|\\left| x_{+} - x_{\\ast}\\right|$と合わせると、\n",
    "$$\n",
    "\\left| w \\right|\\left| x_{+} - x_{\\ast}\\right| = 1\n",
    "$$\n",
    "であることがわかるので、\n",
    "$$\n",
    "\\left| x_{ + }-x_{ \\ast  } \\right| =\\frac { 1 }{ \\left| w \\right|  }\n",
    "$$\n",
    "が導ける。\n",
    "\n",
    "さて、$\\left| x_{ + }-x_{ \\ast  } \\right|$はマージンを表しているので、結局、この分離平面のマージンは$1/\\left| w \\right|$で表されることになる。これを最大化したいのだが、絶対値は扱いにくいので2乗して、$1/w^{2}$を最大化することにする。こうしても求める分離平面は本質的に変わらない。さらに、分数は扱いにくいので、この逆数をとってそれを最小化することにする。つまり、\n",
    "$$\n",
    "\\min {w^{2}}\n",
    "$$\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線形分離可能なSVMモデル\n",
    "マージンが最大になること以外に、当然ながら学習データが正しく分類できる必要がある。$y^{(i)} = +1$であるような学習データについては、$w \\cdot x^{(i)} - b \\ge 1$であればよい(分離平面に**最も近く特徴ベクトルが$w \\cdot x - b = 1$を満たす**のであった)。$y^{(i)} = -1$であるような学習データについては、$w \\cdot x^{(i)} - b \\le -1$であればよい。この二つの条件は次のようにまとめることができる。\n",
    "$$\n",
    "y^{(i)}\\left(w \\cdot x^{(i)} - b\\right) \\ge 1\n",
    "$$\n",
    "よって、これを制約とした次の最適化問題を解けばよい\n",
    "**[主問題]**\n",
    "$$\n",
    "\\min { \\quad \\frac { 1 }{ 2 } { w }^{ 2 } } \\\\\n",
    "s.t.\\quad { y }^{ \\left( i \\right)  }\\left( w\\cdot { x }^{ \\left( i \\right)  }-b \\right) -1\\ge 0;\\forall i\n",
    "$$\n",
    "で定義され、この不等式制約付き最適化問題は、凸計画問題であることがわかる。\n",
    "\n",
    " - ※目的関数に$1/2$がついているが、これはあってもなくても同じであることに注意。あえて付けたのは、単にその後の計算がわかりやすくなるからである。\n",
    "\n",
    "$$\n",
    "L\\left(w,b,\\alpha\\right) = \\frac {1}{2}w^{2} - \\sum _{i}{\\alpha_{i}\\left( { y }^{ \\left( i \\right)  }\\left( w\\cdot { x }^{ \\left( i \\right)  }-b \\right) -1 \\right)}\n",
    "$$\n",
    "これをそれぞれのパラメータで偏微分すると、\n",
    "$$\n",
    "\\left( \\begin{matrix} { \\partial L\\left( w,b,\\alpha  \\right)  }/{ \\partial { w }_{ 1 } } \\\\ \\vdots  \\\\ { \\partial L\\left( w,b,\\alpha  \\right)  }/{ \\partial { w }_{ N } } \\end{matrix} \\right)  = \\nabla_{w}L\\left(w,b,\\alpha\\right) = w - \\sum _{i}{\\alpha_{i}y^{(i)}x^{(i)}}\\\\\n",
    "\\frac { { \\partial L\\left( w,b,\\alpha  \\right)  } }{ { \\partial b } } = \\sum _{i}{\\alpha_{i}y^{(i)}}\n",
    "$$\n",
    "となり、これらを0とおくと、\n",
    "$$\n",
    "{ w }^{ \\ast  }=\\sum _{ i }{ \\alpha _{ i }y^{ (i) }x^{ (i) } } \\\\ \\sum _{ i }{ \\alpha _{ i }y^{ (i) } } =0\n",
    "$$\n",
    "が得られる。一つ目の等式は、分離平面の方向ベクトル$w^{\\ast}$は特徴ベクトルの線形和で表されることを示している。この等式$w^{\\ast} = \\sum _{i}{\\alpha_{i}y^{(i)}x^{(i)}}$を分離平面の式$w \\cdot x = b$に代入すると、\n",
    "$$\n",
    "f\\left(x\\right) = \\sum _{i}{\\alpha_{i}y^{(i)}x^{(i)} \\cdot x - b}\n",
    "$$\n",
    "となる。あとは、$\\alpha_{i}$と$b$を求めれば、分離平面を得ることができる。\n",
    "\n",
    "そこで、これらの等式をもとのラグランジュ関数に代入してみよう。まず、$w^{\\ast} = \\sum _{i}{\\alpha_{i}y^{(i)}x^{(i)}}$を用いると\n",
    "$$\n",
    "L\\left( w^{ \\ast  },b,\\alpha  \\right) =\\frac { 1 }{ 2 } \\sum _{ i,j }{ \\alpha _{ i }\\alpha _{ j }y^{ (i) }y^{ (j) }x^{ (j) }\\cdot x^{ (j) } } -\\sum _{ i }{ \\alpha _{ i }y^{ (i) }\\left( \\sum _{ j }{ \\alpha _{ j }y^{ (j) }x^{ (j) } } \\cdot x^{ (i) }-b \\right)  } +\\sum _{ i }{ \\alpha _{ i } } \\\\ =-\\frac { 1 }{ 2 } \\sum _{ i,j }{ \\alpha _{ i }\\alpha _{ j }y^{ (i) }y^{ (j) }x^{ (j) }\\cdot x^{ (j) } } +b\\sum _{ i }{ \\alpha _{ i }y^{ (i) } } +\\sum _{ i }{ \\alpha _{ i } } \n",
    "$$\n",
    "と変形できる。ここで$\\sum _{ i }{ \\alpha _{ i }y^{ (i) } } =0$なので、\n",
    "$$\n",
    "L\\left( w^{ \\ast  },b,\\alpha  \\right) =\\frac { 1 }{ 2 } \\sum _{ i,j }{ \\alpha _{ i }\\alpha _{ j }y^{ (i) }y^{ (j) }x^{ (i) }\\cdot x^{ (j) } } +\\sum _{ i }{ \\alpha _{ i } } \n",
    "$$\n",
    "となる。これで、もともとの変数$w$と$b$がラグランジュ関数から消去された。ラグランジュの鞍点理論によると、このラグランジュ関数を最大化する$\\alpha_{i}$を求めればよいことがわかる。ただし、$\\sum _{ i }{ \\alpha _{ i }y^{ (i) } } =0, \\quad \\alpha_{i} \\ge 0$という制約のもとでの最大化である。このように最大化問題として**双対問題**が求められる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形分離可能でない場合への拡張\n",
    "*上で導出したSVMであるが、これは実際のデータに対してはなかなかうまく動かない。それは、すべての学習データが正確に分類されなくてはならないという制約${ y }^{ \\left( i \\right)  }\\left( w\\cdot { x }^{ \\left( i \\right)  }-b \\right) -1\\ge 0$があるからである。学習データの中には例外的な特徴ベクトルが存在することが多く、こういったデータによって分離平面が大きく影響を受けてしまうことがよくあるからである。極端なケースでは、もし学習データが線形関数で分離できない場合は、制約を満たす解がそもそも存在しないことになってしまう。*\n",
    "\n",
    "そこで、ここではこの制約を少し緩めることを考える。新たな変数$\\xi_{i}(\\ge 0)$を導入して、\n",
    "$$\n",
    "{ y }^{ \\left( i \\right)  }\\left( w\\cdot { x }^{ \\left( i \\right)  }-b \\right) -1\\ge - \\xi_{i}\n",
    "$$\n",
    "という制約に書き換える。 $\\xi_{i}$は$i$番目の特徴ベクトルがうまく分けられていない度合いを表している。つまり、$\\xi_{i}$は小さいほうがよい。そこで、これを目的関数に加えることにする。新しい最適化問題はつぎのようになる。\n",
    "$$\n",
    "\\min { \\quad \\frac { 1 }{ 2 } { w }^{ 2 }+C\\sum _{ i }{ \\xi _{ i } }  } \\\\ s.t.\\quad { y }^{ \\left( i \\right)  }\\left( w\\cdot { x }^{ \\left( i \\right)  }-b \\right) \\ge 1-\\xi _{ i };\\forall i\\\\ \\qquad \\xi _{ i }\\ge 0;\\forall i\n",
    "$$\n",
    "ここで、$C$は正の定数であり、この値が大きいほどしっかり分類するようになる。逆にこの値が小さければ、例外的な学習データをほとんど無視した分類器ができる。この最適化問題をラグランジュ法を用いて解いてみる。\n",
    "$$\n",
    "L\\left( w,b,\\xi,\\alpha,\\beta \\right) = \\frac {1}{2}w^{2} + C\\sum _{i}{\\xi_{i}} - \\sum _{i}{\\alpha_{i}\\left(y^{(i)}\\left(w \\cdot x^{(i)} - b\\right) - 1 + \\xi_{i}\\right)} - \\sum _{i}{\\beta_{i}\\xi_{i}}\n",
    "$$\n",
    "これをそれぞれのパラメータで偏微分する。\n",
    "$$\n",
    "\\left( \\begin{matrix} { \\partial L\\left( w,b,\\xi ,\\alpha ,\\beta  \\right)  }/{ \\partial { w }_{ 1 } } \\\\ \\vdots  \\\\ { \\partial L\\left( w,b,\\xi ,\\alpha ,\\beta  \\right)  }/{ \\partial { w }_{ N } } \\end{matrix} \\right) =\\nabla _{ w }L\\left( w,b,\\xi ,\\alpha ,\\beta  \\right) =w-\\sum _{ i }{ \\alpha _{ i }y^{ (i) }x^{ (i) } } =0\\\\ \\frac { { \\partial L\\left( w,b,\\xi ,\\alpha ,\\beta  \\right)  } }{ { \\partial b } } =\\sum _{ i }{ \\alpha _{ i }y^{ (i) } } =0\\\\ \\frac { { \\partial L\\left( w,b,\\xi ,\\alpha ,\\beta  \\right)  } }{ { \\partial \\xi  } } =C-\\alpha -\\beta =0\n",
    "$$\n",
    "上式の上二つは、線形分離可能なモデルの場合と同じである。\n",
    "$$\n",
    "{ w }^{ \\ast  }=\\sum _{ i }{ \\alpha _{ i }y^{ (i) }x^{ (i) } } \n",
    "\\\\ \\sum _{ i }{ \\alpha _{ i }y^{ (i) } } =0\\\\ \n",
    "C=\\alpha +\\beta \n",
    "$$\n",
    "双対ラグランジュ関数は、\n",
    "$$\n",
    "L\\left( w^{ \\ast  },b,\\alpha ,\\beta  \\right) =-\\frac { 1 }{ 2 } \\sum _{ i,j }{ \\alpha _{ i }\\alpha _{ j }y^{ (i) }y^{ (j) }x^{ (j) }\\cdot x^{ (j) } } +\\sum _{ i }{ \\alpha _{ i } } +C\\sum _{ i }{ { \\xi  }_{ i } } -\\sum _{ i }{ { \\alpha  }_{ i }{ \\xi  }_{ i } } -\\sum _{ i }{ { \\beta  }_{ i }{ \\xi  }_{ i } } \n",
    "$$\n",
    "となるが最後の３つの項は$C=\\alpha + \\beta$を使うと消去できるので、結局、線形分離可能なモデルの場合と同じになる。これを、$\\alpha _{ i }\\ge 0,\\quad \\beta _{ i }\\ge 0,\\quad \\xi _{ i }\\ge 0$なる条件の下で最大化する。ただし、まず$\\xi_{i}$は双対ラグランジュ関数に登場しないので、とりあえず放っておいてよい。また、$\\beta_{i}$も双対ラグランジュ関数に登場しないので、$\\beta = C - \\alpha_{i} \\ge 0$が満たされていればよい。結局、$\\alpha_{i} \\ge 0$と合わせて、$0 \\le \\alpha_{i} \\le C$なる条件の下で\n",
    "$$\n",
    "\\max { L\\left( w^{ \\ast  },b,\\alpha ,\\beta  \\right) =-\\frac { 1 }{ 2 } \\sum _{ i,j }{ \\alpha _{ i }\\alpha _{ j }y^{ (i) }y^{ (j) }x^{ (j) }\\cdot x^{ (j) } } +\\sum _{ i }{ \\alpha _{ i } }  } \n",
    "$$\n",
    "を最大化することになる。\n",
    "\n",
    "$b$は、$0 < \\alpha_{i} < C$なる特徴ベクトルを一つ持ってきて$b = w \\cdot x^{(i)} - y^{(i)}$とすることで計算できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 関数距離\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非線形SVMの導出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taiyou/.pyenv/versions/anaconda3-2.3.0/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データ数: 4999\n",
      "学習データのうち離職した人数: 2510\n",
      "検証データ数: 2143\n",
      "検証データのうち離職した人数: 1061\n",
      "---モデルの評価---\n",
      "正確度: 0.762949136724\n",
      "適合率: 0.752511415525\n",
      "再現率: 0.776625824694\n",
      "F値: 0.764378478664\n",
      "---分割表---\n",
      "     在籍すると予測  離職すると予測\n",
      "在籍者      811      271\n",
      "離職者      237      824\n",
      "--------------------------------------------------------------\n",
      "学習データ数: 4999\n",
      "学習データのうち離職した人数: 2510\n",
      "検証データ数: 2143\n",
      "検証データのうち離職した人数: 1061\n",
      "---モデルの評価---\n",
      "正確度: 0.934204386374\n",
      "適合率: 0.942307692308\n",
      "再現率: 0.923656927427\n",
      "F値: 0.932889100428\n",
      "---分割表---\n",
      "     在籍すると予測  離職すると予測\n",
      "在籍者     1022       60\n",
      "離職者       81      980\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC # 線形SVM, 非線形SVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "use_cols = [\n",
    "    'satisfaction_level',\n",
    "    'last_evaluation',\n",
    "    'number_project',\n",
    "    'average_montly_hours',\n",
    "    'time_spend_company',\n",
    "    'Work_accident',\n",
    "    'promotion_last_5years',\n",
    "    'salary',\n",
    "    'sales_IT',\n",
    "    'sales_RandD',\n",
    "    'sales_accounting',\n",
    "    'sales_hr',\n",
    "    'sales_management', \n",
    "    'sales_marketing',\n",
    "    'sales_product_mng',\n",
    "    'sales_sales',\n",
    "    'sales_support', \n",
    "    'sales_technical'\n",
    "]\n",
    "\n",
    "# 離職者数:在籍者数 = 1:1に直す\n",
    "X1 = hr_df[hr_df.left == 1][use_cols]\n",
    "X0 = hr_df[hr_df.left == 0][use_cols].sample(len(X1))\n",
    "X = pd.concat([X1, X0])\n",
    "Y = hr_df.loc[X.index, 'left']\n",
    "\n",
    "# 標準化\n",
    "transformed_cols = [\n",
    "    'satisfaction_level',\n",
    "    'last_evaluation',\n",
    "    'number_project',\n",
    "    'average_montly_hours',\n",
    "    'time_spend_company',\n",
    "]\n",
    "ss = StandardScaler()\n",
    "ss.fit(X[transformed_cols])\n",
    "X[transformed_cols] = ss.transform(X[transformed_cols])\n",
    "\n",
    "\n",
    "# 交差検証(ホールドアウト法)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, train_size=0.7, random_state=0)\n",
    "\n",
    "\n",
    "for model in [LinearSVC, SVC]:\n",
    "    linear_svc = model()\n",
    "    linear_svc.fit(x_train, y_train)\n",
    "\n",
    "    print('学習データ数: %s' % x_train.shape[0])\n",
    "    print('学習データのうち離職した人数: %s' % y_train[y_train == 1].shape[0])\n",
    "    print('検証データ数: %s' % x_test.shape[0])\n",
    "    print('検証データのうち離職した人数: %s' % y_test[y_test == 1].shape[0])\n",
    "\n",
    "    y_pred = linear_svc.predict(x_test)\n",
    "\n",
    "    print('---モデルの評価---')\n",
    "    print('正確度: %s' % accuracy_score(y_test, y_pred))\n",
    "    print('適合率: %s' % precision_score(y_test, y_pred))\n",
    "    print('再現率: %s' % recall_score(y_test, y_pred))\n",
    "    print('F値: %s' % f1_score(y_test, y_pred))\n",
    "\n",
    "    print('---分割表---')\n",
    "    confusion_df = pd.DataFrame(confusion_matrix(y_test, y_pred), index=['在籍者', '離職者'], columns=['在籍すると予測', '離職すると予測'])\n",
    "    print(confusion_df)\n",
    "    print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正確度: 0.768272192663\n",
      "適合率: 0.753976670201\n",
      "再現率: 0.796415569868\n",
      "F値: 0.774615279858\n",
      "分割表\n",
      "     在籍すると予測  離職すると予測\n",
      "在籍者     2643      928\n",
      "離職者      727     2844\n",
      "----------------------------------------------------------------------------\n",
      "正確度: 0.934192103052\n",
      "適合率: 0.943887775551\n",
      "再現率: 0.923270792495\n",
      "F値: 0.933465458664\n",
      "分割表\n",
      "     在籍すると予測  離職すると予測\n",
      "在籍者     3375      196\n",
      "離職者      274     3297\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC # 線形SVM, 非線形SVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "use_cols = [\n",
    "    'satisfaction_level',\n",
    "    'last_evaluation',\n",
    "    'number_project',\n",
    "    'average_montly_hours',\n",
    "    'time_spend_company',\n",
    "    'Work_accident',\n",
    "    'promotion_last_5years',\n",
    "    'salary',\n",
    "    'sales_IT',\n",
    "    'sales_RandD',\n",
    "    'sales_accounting',\n",
    "    'sales_hr',\n",
    "    'sales_management', \n",
    "    'sales_marketing',\n",
    "    'sales_product_mng',\n",
    "    'sales_sales',\n",
    "    'sales_support', \n",
    "    'sales_technical'\n",
    "]\n",
    "\n",
    "# 離職者数:在籍者数 = 1:1に直す\n",
    "X1 = hr_df[hr_df.left == 1][use_cols]\n",
    "X0 = hr_df[hr_df.left == 0][use_cols].sample(len(X1))\n",
    "X = pd.concat([X1, X0])\n",
    "Y = hr_df.loc[X.index, 'left']\n",
    "\n",
    "# 標準化\n",
    "transformed_cols = [\n",
    "    'satisfaction_level',\n",
    "    'last_evaluation',\n",
    "    'number_project',\n",
    "    'average_montly_hours',\n",
    "    'time_spend_company',\n",
    "]\n",
    "ss = StandardScaler()\n",
    "ss.fit(X[transformed_cols])\n",
    "X[transformed_cols] = ss.transform(X[transformed_cols])\n",
    "\n",
    "# 交差検証(k-分割交差検証法)\n",
    "CV = 10\n",
    "for model in [LinearSVC, SVC]:\n",
    "    y_pred = cross_val_predict(model(), X, Y, cv=CV)\n",
    "\n",
    "    print('正確度: %s' % accuracy_score(Y, y_pred))\n",
    "    print('適合率: %s' % precision_score(Y, y_pred))\n",
    "    print('再現率: %s' % recall_score(Y, y_pred))\n",
    "    print('F値: %s' % f1_score(Y, y_pred))\n",
    "    print('分割表')\n",
    "    confusion_df = pd.DataFrame(confusion_matrix(Y, y_pred), index=['在籍者', '離職者'], columns=['在籍すると予測', '離職すると予測'])\n",
    "    print(confusion_df)\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC # 線形SVM, 非線形SVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "# Grid searchの詳細\n",
    "# http://qiita.com/SE96UoC5AfUt7uY/items/c81f7cea72a44a7bfd3a\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "use_cols = [\n",
    "    'satisfaction_level',\n",
    "    'last_evaluation',\n",
    "    'number_project',\n",
    "    'average_montly_hours',\n",
    "    'time_spend_company',\n",
    "    'Work_accident',\n",
    "    'promotion_last_5years',\n",
    "    'salary',\n",
    "    'sales_IT',\n",
    "    'sales_RandD',\n",
    "    'sales_accounting',\n",
    "    'sales_hr',\n",
    "    'sales_management', \n",
    "    'sales_marketing',\n",
    "    'sales_product_mng',\n",
    "    'sales_sales',\n",
    "    'sales_support', \n",
    "    'sales_technical'\n",
    "]\n",
    "\n",
    "# アンダーサンプリング(離職者数:在籍者数 = 1:1に直す)\n",
    "X1 = hr_df[hr_df.left == 1][use_cols]\n",
    "X0 = hr_df[hr_df.left == 0][use_cols].sample(len(X1))\n",
    "X = pd.concat([X1, X0])\n",
    "Y = hr_df.loc[X.index, 'left']\n",
    "\n",
    "# 標準化\n",
    "transformed_cols = [\n",
    "    'satisfaction_level',\n",
    "    'last_evaluation',\n",
    "    'number_project',\n",
    "    'average_montly_hours',\n",
    "    'time_spend_company',\n",
    "]\n",
    "ss = StandardScaler()\n",
    "ss.fit(X[transformed_cols])\n",
    "X[transformed_cols] = ss.transform(X[transformed_cols])\n",
    "\n",
    "# Grid searchのパラメータ\n",
    "parameters = [\n",
    "        {'C': [1, 10, 100, 1000], 'kernel': ['linear']}, # 線形カーネル\n",
    "        {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.001, 0.0001]}, # RBFカーネル\n",
    "        {'C': [1, 10, 100, 1000], 'kernel': ['poly'], 'degree': [2, 3, 4], 'gamma': [0.001, 0.0001]}, # 多項式カーネル\n",
    "        {'C': [1, 10, 100, 1000], 'kernel': ['sigmoid'], 'gamma': [0.001, 0.0001]} # シグモイドカーネル\n",
    "    ]\n",
    "\n",
    "SCORE = 'f1'\n",
    "CV = 10\n",
    "\n",
    "clf = GridSearchCV(\n",
    "        SVC(), # 識別器\n",
    "        parameters, # 最適化したいパラメータセット \n",
    "        cv=CV, # 交差検定の回数\n",
    "        scoring='%s_weighted' % SCORE # モデルの評価関数の指定\n",
    "    )\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(clf.grid_scores_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(clf.best_estimator_, X, Y, cv=CV)\n",
    "\n",
    "print('正確度: %s' % accuracy_score(Y, y_pred))\n",
    "print('適合率: %s' % precision_score(Y, y_pred))\n",
    "print('再現率: %s' % recall_score(Y, y_pred))\n",
    "print('F値: %s' % f1_score(Y, y_pred))\n",
    "print('分割表')\n",
    "confusion_df = pd.DataFrame(confusion_matrix(Y, y_pred), index=['在籍者', '離職者'], columns=['在籍すると予測', '離職すると予測'])\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
